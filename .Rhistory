# Suppression des valeurs aberrantes
albu_sulfo2$albumine[index_outliers] = NaN
}
boxplot(albu_sulfo2$albumine)
# Filtrer les données
(albu_non_undu <- data3[data3$type_albumine == "Albumin.unadducted",])
albu_non_undu2 = albu_non_undu
# Calculer les valeurs aberrantes
# Prend les valeurs supérieures ou inférieurs aux quartiles +-1.5 fois l'écart interquartile
(outliers <- boxplot.stats(data$Albumin.unadducted)$out)
# Afficher les indes des valeurs aberrantes
(index_outliers = which(data$Albumin.unadducted %in% c(outliers)))
# Suppression des valeurs aberrantes
albu_non_undu$albumine[index_outliers] = NaN
boxplot(albu_non_undu$albumine)
for (i in levels(data$smoking_status)){
outliers = boxplot.stats(data$Albumin.unadducted[data$smoking_status == i])$out
index_outliers = which(data$Albumin.unadducted %in% c(outliers))
# Affiche les valeurs détéctées
print(i)
print(outliers)
# Suppression des valeurs aberrantes
albu_non_undu2$albumine[index_outliers] = NaN
}
boxplot(albu_non_undu2$albumine)
val_albu2 = c(albu_CysGly2$albumine, albu_Nacetyl2$albumine, albu_sulfo2$albumine, albu_non_undu2$albumine)
type_Albumine = c(albu_CysGly$type_albumine, albu_Nacetyl$type_albumine, albu_sulfo$type_albumine, albu_non_undu$type_albumine)
data_corr_graph2 = data.frame(val_albu2, type_Albumine)
data_corr_graph2
albu_non_undu2$albumine
albu_non_undu$type_albumine
data_corr_graph2
library(ggplot2)
val_albu = c(albu_CysGly$albumine, albu_Nacetyl$albumine, albu_sulfo$albumine, albu_non_undu$albumine)
data_corr_graph = data.frame(val_albu, type_Albumine)
# boxplot général pour voir que c'est mieux
ggplot(data_corr_graph, aes(x=type_Albumine,y=val_albu, fill=type_Albumine)) +
geom_boxplot()+
xlab(label = "Différents types d'albumines") +
ylab(label = "Concentration") +
theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
theme(legend.position="none")+
ggtitle("Boxplot des différentes albumines")
ggplot(data_corr_graph2, aes(x=type_Albumine,y=val_albu2, fill=type_Albumine)) +
geom_boxplot()+
xlab(label = "Différents types d'albumines") +
ylab(label = "Concentration") +
theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
theme(legend.position="none")+
ggtitle("Boxplot des différentes albumines")
ggplot(data_corr_graph2, aes(x=type_Albumine,y=val_albu2, fill=type_Albumine)) +
geom_boxplot()+
xlab(label = "Différents types d'albumines") +
ylab(label = "Concentration") +
theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
theme(legend.position="none")+
ggtitle("Boxplot des différentes albumines")+
ylim(c(0,5))
ggplot(data_corr_graph2, aes(x=type_Albumine,y=val_albu2, fill=type_Albumine)) +
geom_boxplot()+
xlab(label = "Différents types d'albumines") +
ylab(label = "Concentration") +
theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
theme(legend.position="none")+
ggtitle("Boxplot des différentes albumines")+
ylim(c(0,10))
data$CysGly_corr2 = albu_CysGly2$albumine
data$Nacetyl_corr2 = albu_Nacetyl2$albumine
data$sulfo_corr2 = albu_sulfo2$albumine
data$unadducted_corr2 = albu_non_undu2$albumine
tapply(data$CysGly_corr2, data$smoking_status, mean)
tapply(na.omit(data$CysGly_corr2), data$smoking_status, mean)
tapply(na.omit(data$CysGly_corr2), data$smoking_status[data$CysGly_corr2 == na.omit(data$CysGly_corr2)], mean)
data$smoking_status[data$CysGly_corr2 == na.omit(data$CysGly_corr2)
data$smoking_status[data$CysGly_corr2 == na.omit(data$CysGly_corr2)]
data$CysGly_corr2 == na.omit(data$CysGly_corr2)
data$CysGly_corr2
na.omit(data$CysGly_corr2)
tapply(na.omit(data$CysGly_corr2), data$smoking_status[data$CysGly_corr2 != NaN], mean)
data$CysGly_corr2 != NaN
data$CysGly_corr2 == NaN
mean(na.omit(data$CysGly_cor[data$smoking_status == "Former"]),)
mean(na.omit(data$CysGly_cor[data$smoking_status == "Current"]),)
mean(na.omit(data$CysGly_cor[data$smoking_status == "Never"]),)
mean(na.omit(data$CysGly_corr2[data$smoking_status == "Former"]),)
mean(na.omit(data$CysGly_corr2[data$smoking_status == "Current"]),)
mean(na.omit(data$CysGly_corr2[data$smoking_status == "Never"]),)
# Implémantation dans le tableau à l'origine
data$CysGly_cor = albu_CysGly$albumine
data$Nacetyl_corr = albu_Nacetyl$albumine
data$sulfo_corr = albu_sulfo$albumine
data$unadducted_corr = albu_non_undu$albumine
mean(na.omit(data$CysGly_cor[data$smoking_status == "Former"]),)
mean(na.omit(data$CysGly_cor[data$smoking_status == "Current"]),)
mean(na.omit(data$CysGly_cor[data$smoking_status == "Never"]),)
mean(na.omit(data$CysGly_corr2[data$smoking_status == "Former"]),)
mean(na.omit(data$CysGly_corr2[data$smoking_status == "Current"]),)
mean(na.omit(data$CysGly_corr2[data$smoking_status == "Never"]),)
mean(na.omit(data$sulfo_corr[data$smoking_status == "Former"]),)
mean(na.omit(data$sulfo_corr[data$smoking_status == "Current"]),)
mean(na.omit(data$sulfo_corr[data$smoking_status == "Never"]),)
mean(na.omit(data$sulfo_corr2[data$smoking_status == "Former"]),)
mean(na.omit(data$sulfo_corr2[data$smoking_status == "Current"]),)
mean(na.omit(data$sulfo_corr2[data$smoking_status == "Never"]),)
# moyenne Nacetyl selon état tabagique
mean(na.omit(data$Nacetyl_corr[data$smoking_status == "Former"]),)
mean(na.omit(data$Nacetyl_corr[data$smoking_status == "Current"]),)
mean(na.omit(data$Nacetyl_corr[data$smoking_status == "Never"]),)
mean(na.omit(data$Nacetyl_corr2[data$smoking_status == "Former"]),)
mean(na.omit(data$Nacetyl_corr2[data$smoking_status == "Current"]),)
mean(na.omit(data$Nacetyl_corr2[data$smoking_status == "Never"]),)
# moyenne non adducté selon état tabagique
mean(na.omit(data$unadducted_corr[data$smoking_status == "Former"]),)
mean(na.omit(data$unadducted_corr[data$smoking_status == "Current"]),)
mean(na.omit(data$unadducted_corr[data$smoking_status == "Never"]),)
mean(na.omit(data$unadducted_corr2[data$smoking_status == "Former"]),)
mean(na.omit(data$unadducted_corr2[data$smoking_status == "Current"]),)
mean(na.omit(data$unadducted_corr2[data$smoking_status == "Never"]),)
# Les tests
wilcox.test(data$CysGly_cor[data$case == "0"], data$CysGly_cor[data$case == "1"])
wilcox.test(data$Albumin.adduct.of.CysGly[data$case == "0"], data$Albumin.adduct.of.CysGly[data$case == "1"])
wilcox.test(data$CysGly_corr2[data$case == "0"], data$CysGly_corr2[data$case == "1"])
summary(glm(data$case ~ data$CysGly_corr2, family = "binomial"))
############# Nacetyl ##############
wilcox.test(data$Nacetyl_corr[data$case == "0"], data$Nacetyl_corr[data$case == "1"])
wilcox.test(data$Albumin.adduct.of.Nacetylcysteine[data$case == "0"], data$Albumin.adduct.of.Nacetylcysteine[data$case == "1"])
wilcox.test(data$Nacetyl_corr2[data$case == "0"], data$Nacetyl_corr2[data$case == "1"])
############ Non adductée ###########
wilcox.test(data$Albumin.unadducted[data$case == "0"], data$Albumin.unadducted[data$case == "1"])
summary(glm(data$case ~ data$Albumin.unadducted, family = "binomial"))
wilcox.test(data$unadducted_corr[data$case == "0"], data$unadducted_corr[data$case == "1"])
summary(glm(data$case ~ data$unadducted_corr, family = "binomial"))
wilcox.test(data$unadducted_corr2[data$case == "0"], data$unadducted_corr2[data$case == "1"])
summary(glm(data$case ~ data$unadducted_corr2, family = "binomial"))
########### Acide sulfonique ##########
wilcox.test(data$sulfo_corr[data$case == "0"], data$sulfo_corr[data$case == "1"])
summary(glm(data$case ~ data$sulfo_corr, family = "binomial"))
wilcox.test(data$Albumin.adduct.of.sulfonic.acid[data$case == "0"], data$Albumin.adduct.of.sulfonic.acid[data$case == "1"])
summary(glm(data$case ~ data$Albumin.adduct.of.sulfonic.acid, family = "binomial"))
wilcox.test(data$sulfo_corr2[data$case == "0"], data$sulfo_corr2[data$case == "1"])
wilcox.test(data$Albumin.adduct.of.sulfonic.acid[data$case == "0"], data$Albumin.adduct.of.sulfonic.acid[data$case == "1"])
########### Acide sulfonique ##########
wilcox.test(data$sulfo_corr[data$case == "0"], data$sulfo_corr[data$case == "1"])
summary(glm(data$case ~ data$sulfo_corr2, family = "binomial"))
##### TEst kruskall  ####
kruskal.test(data$CysGly_cor, data$smoking_status)
kruskal.test(data$CysGly_corr2, data$smoking_status)
kruskal.test(data$Albumin.adduct.of.CysGly, data$smoking_status)
kruskal.test(data$Nacetyl_corr, data$smoking_status)
kruskal.test(data$Nacetyl_corr2, data$smoking_status)
kruskal.test(data$Albumin.adduct.of.Nacetylcysteine, data$smoking_status)
dunn.test(data$Nacetyl_corr, data$smoking_status,  method = "bonferroni")
library(dunn.test)
kruskal.test(data$Albumin.adduct.of.Nacetylcysteine, data$smoking_status)
dunn.test(data$Albumin.adduct.of.Nacetylcysteine, data$smoking_status,  method = "bonferroni")
dunn.test(data$Nacetyl_corr2, data$smoking_status,  method = "bonferroni")
dunn.test(data$Nacetyl_corr, data$smoking_status,  method = "bonferroni")
dunn.test(data$Nacetyl_corr2, data$smoking_status,  method = "bonferroni")
wilcox.test(data$Nacetyl_corr2[data$smoking_status == "Former"], data$Nacetyl_corr2[data$smoking_status == "Never"] )
wilcox.test(data$Nacetyl_corr2[data$smoking_status == "Current"], data$Nacetyl_corr2[data$smoking_status == "Never"] )
dunn.test(data$Nacetyl_corr2, data$smoking_status,  method = "bonferroni")
wilcox.test(data$Nacetyl_corr2[data$smoking_status == "Current"], data$Nacetyl_corr2[data$smoking_status == "Former"] )
kruskal.test(data$Albumin.unadducted, data$smoking_status)
dunn.test(data$Albumin.unadducted, data$smoking_status,  method = "bonferroni")
kruskal.test(data$unadducted_corr2, data$smoking_status)
kruskal.test(data$unadducted_corr, data$smoking_status)
kruskal.test(data$Albumin.unadducted, data$smoking_status)
dunn.test(data$unadducted_corr2, data$smoking_status,  method = "bonferroni")
kruskal.test(data$Albumin.adduct.of.sulfonic.acid, data$smoking_status)
kruskal.test(data$sulfo_corr, data$smoking_status)
kruskal.test(data$sulfo_corr2, data$smoking_status)
dunn.test(data$sulfo_corr2, data$smoking_status)
# Ecart type
ecart_types_par_etat <- tapply(data$CysGly_cor, data$smoking_status, sd)
# barplot
bp = barplot(height = moyennes_par_etat, col = "skyblue", main = "CysGly", ylim = c(0,5) )
# Barre d'erreur sd
arrows(bp, moyennes_par_etat, bp, moyennes_par_etat + ecart_types_par_etat, angle = 90, code = 3, length = 0.1, col = "black")
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(Case ~ ., data = train_data, ntree = 100))
library(randomForest)
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(Case ~ ., data = train_data, ntree = 100))
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(case ~ ., data = train_data, ntree = 100))
# ========================= RAndom Forest
data = read.csv("LC-Adductomics.csv")
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(case ~ ., data = train_data, ntree = 100))
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(predictions == test_data$Species) / nrow(test_data))
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100))
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(predictions == test_data$Species) / nrow(test_data))
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
remove(data$Code.participants)
data$Code.participants = NULL
data$centre = NULL
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100))
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(predictions == test_data$Species) / nrow(test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(predictions == test_data$case) / nrow(test_data))
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
barplot(sorted_importance, horiz = F, main = "Importance des Caractéristiques", xlab = "Scored d'importance",
cex.names =0.8, las = 1)
(df = as.data.frame(sorted_importance))
ggplot(geom_bar(data = df))
ggplot(geom_bar(df))
ggplot(df, aes(x = row.names(df), y = df$sorted_importance , fill = colnames(vac2))) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Réaction", y = "Valeur", fill = "Traitement") +
theme_minimal()
(df = as.data.frame(sorted_importance))
rownames(df)
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Réaction", y = "Valeur", fill = "Traitement") +
theme_minimal()
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Réaction", y = "Valeur", fill = "Traitement")
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity", position = "dodge")
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar()
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(aes)
stat = "identity"
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")+
xlim(c(0.2))
ggplot(df, aes(x = df$sorted_importance, y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")+
xlim(c(0,2))
ggplot(df, aes(x = rownames(df), y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")+
xlim(c(0,5))
ggplot(df, aes(x = rownames(df), y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")+
xlim(c(0,5))
ggplot(df, aes(x = rownames(df), y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")
ggplot(df, aes(x = rownames(df), y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")+
theme_minimal()
data$Albumin.adduct.of.Nacetylcysteine = NULL
data$Albumin.adduct.of.CysGly = NULL
data$Albumin.adduct.of.Nacetylcysteine = NULL
data$Albumin.unadducted= NULL
data$Albumin.adduct.of.sulfonic.acid = NULL
data$Albumin.adduct.of.CysGly = NULL
data$CysGly_corr2 = albu_CysGly2$albumine
data$Nacetyl_corr2 = albu_Nacetyl2$albumine
data$sulfo_corr2 = albu_sulfo2$albumine
data$unadducted_corr2 = albu_non_undu2$albumine
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100))
help(randomForest)
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit()))
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit)
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(predictions == test_data$case) / nrow(test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
barplot(sorted_importance, horiz = F, main = "Importance des Caractéristiques", xlab = "Scored d'importance",
cex.names =0.8, las = 1)
(df = as.data.frame(sorted_importance))
ggplot(df, aes(x = rownames(df), y = df$sorted_importance , fill = rownames(df))) +
geom_bar(stat = "identity")+
theme_minimal()
rownames(df)
rownames(df)
# ========================= RAndom Forest
data = read.csv("LC-Adductomics.csv")
data$Code.participants = NULL
data$centre = NULL
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
for (i in seq(1:10)){
print(i)
}
for (i in seq(1:10)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
}
# ========================= RAndom Forest
data = read.csv("LC-Adductomics.csv")
data$Code.participants = NULL
data$centre = NULL
for (i in seq(1:10)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
print(accuracy)
print(sorted_importance)
}
for (i in seq(1:100)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
precision = c(precision, accuracy)
print(mean(precision))
print(sorted_importance)
}
precision = c()
for (i in seq(1:100)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
precision = c(precision, accuracy)
print(mean(precision))
print(sorted_importance)
}
for (i in seq(1:100)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
precision = c(precision, accuracy)
# print(sorted_importance)
}
print(mean(precision))
for (i in seq(1:100)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
precision = c(precision, accuracy)
print(i)
# print(sorted_importance)
}
print(mean(precision)) # Après 100 tours, précision moyenne de 56%
for (i in seq(1:200)){
# Préparation des données 70 apprentissage et 30 de test
# Ressort 70% des lignes
(train_idx = sample(1:nrow(data), 0.7*nrow(data)))
(train_data = data[train_idx,])
(test_data = data[-train_idx,])
dim(test_data) # 45 données
dim(train_data) # 105 données
# Prédiction de l'espèce en fonction des autres variables en utilisant 100 arbres
(rf_model = randomForest(as.factor(case) ~ ., data = train_data, ntree = 100, na.action = na.omit))
help(randomForest)
# Predictions des espèces sur les données test
(predictions = predict(rf_model, test_data))
# Calcul le nombre de bonnes prédictions en %
(accuracy = sum(na.omit(predictions) == test_data$case) / nrow(test_data))
# 97.8% donc le modèle a une exactitude plus que satisfaisante
# Extrait les variables les plus importantes
(features_importance = importance(rf_model))
(sorted_importance = features_importance[order(-features_importance),])
precision = c(precision, accuracy)
print(i)
# print(sorted_importance)
}
print(mean(precision)) # Après 100 tours, précision moyenne de 56%
